{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import GammaRegressor\n",
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n",
    "from datetime import datetime\n",
    "import statsmodels.discrete.count_model as reg_models\n",
    "import statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "tweets = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86488, 11)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tweets[tweets.retweet_count > 10].copy()\n",
    "X = X[X.retweet_count < 1000]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15848</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10424</td>\n",
       "      <td>3083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hashtag_count  user_verified  user_statuses_count  user_followers_count\n",
       "17              0              0                15848                  1257\n",
       "24              0              0                10424                  3083\n",
       "43              7              0                   24                   146"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X.retweet_count.copy()\n",
    "X = X[['user_verified', 'user_statuses_count', 'user_followers_count']]\n",
    "# adding extra features : size of the text\n",
    "#X.insert(0, 'size_text', tweets.text.apply(lambda x: len(x)), True)\n",
    "\n",
    "# adding extra features : number of hashtags\n",
    "def count_hashtags_in_text(text):\n",
    "    return text.count('#')\n",
    "X.insert(0, 'hashtag_count', tweets.text.apply(count_hashtags_in_text), True)\n",
    "\n",
    "# Converting timestamp in hour\n",
    "def timestamp_13_digits_to_hour(t):\n",
    "    dt = datetime.fromtimestamp(t / 1000)\n",
    "    return dt.hour\n",
    "#X.timestamp = X.timestamp.apply(timestamp_13_digits_to_hour)\n",
    "\n",
    "# Converting the True / False values of user_verified into 1 / 0\n",
    "X['user_verified'] = (X['user_verified']).astype(int)\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.user_statuses_count = np.log(1 + X.user_statuses_count)\n",
    "X.user_followers_count = np.log(1 + X.user_followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602709</td>\n",
       "      <td>0.385741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.434204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169562</td>\n",
       "      <td>0.269712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hashtag_count  user_verified  user_statuses_count  user_followers_count\n",
       "0       0.000000            0.0             0.602709              0.385741\n",
       "1       0.000000            0.0             0.574586              0.434204\n",
       "2       0.241379            0.0             0.169562              0.269712"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Center and normalize the datas\n",
    "X = X - X.mean()\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_worst(estimators):\n",
    "    mae_test, mae_train = 0, 0\n",
    "    sgd = None\n",
    "    for esti in estimators:\n",
    "        y_test_sgd = esti.predict(X_test)\n",
    "        y_test_sgd = y_test_sgd.astype(int)\n",
    "        y_train_sgd = esti.predict(X_train)\n",
    "        y_train_sgd = y_train_sgd.astype(int)\n",
    "        cur_mae_test = mean_absolute_error(y_true=y_test, y_pred=y_test_sgd)\n",
    "        cur_mae_train = mean_absolute_error(y_true=y_train, y_pred=y_train_sgd)\n",
    "        if cur_mae_test > mae_test:\n",
    "            mae_test = cur_mae_test\n",
    "            mae_train = cur_mae_train\n",
    "            sgd = esti\n",
    "    print(\"Prediction error on test set :\", mae_test)\n",
    "    print(\"Prediction error on train set :\", mae_train)\n",
    "    \n",
    "    return sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying SGD regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 122.35591783250472\n",
      "Prediction error on train set : 122.14713995474142\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDRegressor(max_iter=1000, tol=1e-4)\n",
    "sgd_estimators = cross_validate(sgd, X, y, return_estimator=True)['estimator']\n",
    "sgd = cv_worst(sgd_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 74.7800411 ,  24.21144994,  54.7927342 , ..., 146.17335787,\n",
       "       152.69062832, 170.22497593])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 122.35591783250472\n",
      "Prediction error on train set : 122.14713995474142\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr_estimators = cross_validate(lr, X, y, return_estimator=True)['estimator']\n",
    "lr = cv_worst(sgd_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 features : Index(['size_text'], dtype='object')\n",
      "X2 features : Index(['size_text'], dtype='object')\n",
      "Prediction error spearman for top 1 features with SGD : 151.09559714420178\n",
      "Prediction error spearman for top 1 features with LinReg : 151.070403636837\n",
      "Prediction error pearson  for top 1 features with SGD : 151.06950744490172\n",
      "Prediction error pearson  for top 1 features with LinReg : 151.070403636837\n",
      "X1 features : Index(['hashtag_count', 'size_text'], dtype='object')\n",
      "X2 features : Index(['size_text', 'user_followers_count'], dtype='object')\n",
      "Prediction error spearman for top 2 features with SGD : 151.04894509697897\n",
      "Prediction error spearman for top 2 features with LinReg : 151.04478456346942\n",
      "Prediction error pearson  for top 2 features with SGD : 151.33287772737742\n",
      "Prediction error pearson  for top 2 features with LinReg : 156.447955781189\n",
      "X1 features : Index(['hashtag_count', 'size_text', 'user_followers_count'], dtype='object')\n",
      "X2 features : Index(['hashtag_count', 'size_text', 'user_followers_count'], dtype='object')\n",
      "Prediction error spearman for top 3 features with SGD : 151.04953588272403\n",
      "Prediction error spearman for top 3 features with LinReg : 150.1185326484224\n",
      "Prediction error pearson  for top 3 features with SGD : 151.13347251844954\n",
      "Prediction error pearson  for top 3 features with LinReg : 150.1185326484224\n",
      "X1 features : Index(['hashtag_count', 'size_text', 'user_verified', 'user_followers_count'], dtype='object')\n",
      "X2 features : Index(['hashtag_count', 'size_text', 'user_statuses_count',\n",
      "       'user_followers_count'],\n",
      "      dtype='object')\n",
      "Prediction error spearman for top 4 features with SGD : 151.0574514103758\n",
      "Prediction error spearman for top 4 features with LinReg : 150.01077933651757\n",
      "Prediction error pearson  for top 4 features with SGD : 151.06884155927384\n",
      "Prediction error pearson  for top 4 features with LinReg : 149.39939119028307\n",
      "X1 features : Index(['hashtag_count', 'size_text', 'user_verified', 'user_followers_count',\n",
      "       'user_friends_count'],\n",
      "      dtype='object')\n",
      "X2 features : Index(['hashtag_count', 'size_text', 'user_statuses_count',\n",
      "       'user_followers_count', 'user_friends_count'],\n",
      "      dtype='object')\n",
      "Prediction error spearman for top 5 features with SGD : 151.03394514704556\n",
      "Prediction error spearman for top 5 features with LinReg : 149.74390939950135\n",
      "Prediction error pearson  for top 5 features with SGD : 151.02100794056093\n",
      "Prediction error pearson  for top 5 features with LinReg : 149.18815023981895\n",
      "X1 features : Index(['hashtag_count', 'size_text', 'user_verified', 'user_statuses_count',\n",
      "       'user_followers_count', 'user_friends_count'],\n",
      "      dtype='object')\n",
      "X2 features : Index(['hashtag_count', 'size_text', 'user_verified', 'user_statuses_count',\n",
      "       'user_followers_count', 'user_friends_count'],\n",
      "      dtype='object')\n",
      "Prediction error spearman for top 6 features with SGD : 151.0180490051769\n",
      "Prediction error spearman for top 6 features with LinReg : 149.21557671703366\n",
      "Prediction error pearson  for top 6 features with SGD : 150.9887650575265\n",
      "Prediction error pearson  for top 6 features with LinReg : 149.21557671703366\n",
      "X1 features : Index(['hashtag_count', 'size_text', 'timestamp', 'user_verified',\n",
      "       'user_statuses_count', 'user_followers_count', 'user_friends_count'],\n",
      "      dtype='object')\n",
      "X2 features : Index(['hashtag_count', 'size_text', 'timestamp', 'user_verified',\n",
      "       'user_statuses_count', 'user_followers_count', 'user_friends_count'],\n",
      "      dtype='object')\n",
      "Prediction error spearman for top 7 features with SGD : 151.04708261988443\n",
      "Prediction error spearman for top 7 features with LinReg : 149.19283647250845\n",
      "Prediction error pearson  for top 7 features with SGD : 150.96653549220463\n",
      "Prediction error pearson  for top 7 features with LinReg : 149.19283647250845\n",
      "Wall time: 6.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for k in range(1, len(corr_features1) + 1):\n",
    "    to_remove1 = corr_features1[k:]\n",
    "    to_remove2 = corr_features2[k:]\n",
    "    X1_train, X2_train = X_train.copy(), X_train.copy()\n",
    "    X1_test, X2_test = X_test.copy(), X_test.copy()\n",
    "    for f, _ in to_remove1:\n",
    "        X1_train.drop(f, axis=1, inplace=True)\n",
    "        X1_test.drop(f, axis=1, inplace=True)\n",
    "    for f, _ in to_remove2:\n",
    "        X2_train.drop(f, axis=1, inplace=True)\n",
    "        X2_test.drop(f, axis=1, inplace=True)\n",
    "    print(\"X1 features :\", X1_train.columns)\n",
    "    print(\"X2 features :\", X2_train.columns)\n",
    "    # Spearman k features\n",
    "    \n",
    "    sgd = SGDRegressor(max_iter=1000, tol=1e-4)\n",
    "    sgd.fit(X1_train, y_train)\n",
    "    y_pred = sgd.predict(X1_test)\n",
    "    y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    print(\"Prediction error spearman for top\", k, \"features with SGD :\", mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X1_train, y_train)\n",
    "    y_pred = lin_reg.predict(X1_test)\n",
    "    y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    print(\"Prediction error spearman for top\", k, \"features with LinReg :\", mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    #rf = RandomForestRegressor(max_depth=3, random_state=1)\n",
    "    #rf.fit(X1_train, y_train)\n",
    "    #y_pred = rf.predict(X1_test)\n",
    "    #y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    #print(\"Prediction error spearman for top\", k, \"features with RF :\", mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    # Pearson k features\n",
    "    \n",
    "    sgd = SGDRegressor(max_iter=1000, tol=1e-4)\n",
    "    sgd.fit(X2_train, y_train)\n",
    "    y_pred = sgd.predict(X2_test)\n",
    "    y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    print(\"Prediction error pearson  for top\", k, \"features with SGD :\", mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X2_train, y_train)\n",
    "    y_pred = lin_reg.predict(X2_test)\n",
    "    y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    print(\"Prediction error pearson  for top\", k, \"features with LinReg :\", mean_absolute_error(y_true=y_test, y_pred=y_pred))\n",
    "    \n",
    "    #rf = RandomForestRegressor(max_depth=3, random_state=1)\n",
    "    #rf.fit(X2_train, y_train)\n",
    "    #y_pred = rf.predict(X2_test)\n",
    "    #y_pred = map_y_inv(y_pred, mu, theta)\n",
    "    #print(\"Prediction error pearson  for top\", k, \"features with RF :\", mean_absolute_error(y_true=y_test, y_pred=y_pred),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_followers_count 0.3221642112952114\n",
      "hashtag_count -0.16490851466947581\n",
      "user_verified 0.15683094634737596\n",
      "user_statuses_count 0.083429547724099\n",
      "size_text -0.0510814980325843\n",
      "user_friends_count 0.015914010304418535\n",
      "timestamp 0.014855101256478074\n"
     ]
    }
   ],
   "source": [
    "# Spearman correlation : for non-linear correlations\n",
    "corr_features1 = [(f, spearmanr(X[f], y).correlation) for f in X.columns]\n",
    "corr_features1.sort(key=lambda x: abs(x[1]))\n",
    "corr_features1.reverse()\n",
    "for f, c in corr_features1:\n",
    "    print(f, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size_text 0.01298010552309922\n",
      "user_followers_count 0.002728900490642274\n",
      "user_statuses_count 0.0027003617908016803\n",
      "user_friends_count 0.0010311370315126398\n",
      "timestamp -0.0009214990207110241\n",
      "user_verified 0.00047234255320145367\n",
      "hashtag_count -0.0003838755670459721\n"
     ]
    }
   ],
   "source": [
    "# Pearson correlation : for linear correlations\n",
    "corr_features2 = [(f, X[f].corr(y)) for f in X.columns]\n",
    "corr_features2.sort(key=lambda x: abs(x[1]))\n",
    "corr_features2.reverse()\n",
    "for f, c in corr_features2:\n",
    "    print(f, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_prediction_file(eval_data, y_pred):\n",
    "    with open(\"gbr_predictions.txt\", 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"TweetID\", \"NoRetweets\"])\n",
    "        for index, prediction in enumerate(y_pred):\n",
    "            writer.writerow([str(eval_data['id'].iloc[index]) , str(int(prediction))])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
