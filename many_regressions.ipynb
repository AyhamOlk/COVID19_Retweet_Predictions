{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "tweets = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86488, 11)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ransta = 0\n",
    "X = tweets[tweets.retweet_count > 10].copy()\n",
    "X = X[X.retweet_count < 1000]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>15848</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>10424</td>\n",
       "      <td>3083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_verified  user_statuses_count  user_followers_count\n",
       "17              0                15848                  1257\n",
       "24              0                10424                  3083\n",
       "43              0                   24                   146"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X.retweet_count.copy()\n",
    "X = X[['user_verified', 'user_statuses_count', 'user_followers_count']]\n",
    "# adding extra features : size of the text\n",
    "#X.insert(0, 'size_text', tweets.text.apply(lambda x: len(x)), True)\n",
    "\n",
    "# adding extra features : number of hashtags\n",
    "def count_hashtags_in_text(text):\n",
    "    return text.count('#')\n",
    "#X.insert(0, 'hashtag_count', tweets.text.apply(count_hashtags_in_text), True)\n",
    "\n",
    "# Converting timestamp in hour\n",
    "def timestamp_13_digits_to_hour(t):\n",
    "    dt = datetime.fromtimestamp(t / 1000)\n",
    "    return dt.hour\n",
    "#X.timestamp = X.timestamp.apply(timestamp_13_digits_to_hour)\n",
    "\n",
    "# Converting the True / False values of user_verified into 1 / 0\n",
    "X['user_verified'] = (X['user_verified']).astype(int)\n",
    "\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.user_statuses_count = np.log(1 + X.user_statuses_count)\n",
    "X.user_followers_count = np.log(1 + X.user_followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.insert(3, 'stat_sqr', X.user_statuses_count ** 2, True)\n",
    "#X.insert(4, 'followers_sqr', X.user_followers_count ** 2, True)\n",
    "#X.insert(5, 'verified_exp', np.exp(X.user_verified), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602709</td>\n",
       "      <td>0.385741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.434204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.169562</td>\n",
       "      <td>0.269712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_verified  user_statuses_count  user_followers_count\n",
       "0            0.0             0.602709              0.385741\n",
       "1            0.0             0.574586              0.434204\n",
       "2            0.0             0.169562              0.269712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Center and normalize the datas\n",
    "X = X - X.mean()\n",
    "scaler = MinMaxScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_worst(estimators):\n",
    "    mae_test, mae_train = 0, 0\n",
    "    sgd = None\n",
    "    for esti in estimators:\n",
    "        y_test_sgd = esti.predict(X_test)\n",
    "        y_test_sgd = y_test_sgd.astype(int)\n",
    "        y_train_sgd = esti.predict(X_train)\n",
    "        y_train_sgd = y_train_sgd.astype(int)\n",
    "        cur_mae_test = mean_absolute_error(y_true=y_test, y_pred=y_test_sgd)\n",
    "        cur_mae_train = mean_absolute_error(y_true=y_train, y_pred=y_train_sgd)\n",
    "        if cur_mae_test > mae_test:\n",
    "            mae_test = cur_mae_test\n",
    "            mae_train = cur_mae_train\n",
    "            sgd = esti\n",
    "    print(\"Prediction error on test set :\", mae_test)\n",
    "    print(\"Prediction error on train set :\", mae_train)\n",
    "    \n",
    "    return sgd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying SGD regression with huber loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 102.80922650017344\n",
      "Prediction error on train set : 102.50742472043738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd = SGDRegressor(max_iter=1000, tol=1e-4, random_state=ransta, loss='huber')\n",
    "sgd_estimators = cross_validate(sgd, X, y, return_estimator=True)['estimator']\n",
    "sgd = cv_worst(sgd_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 120.77373106717539\n",
      "Prediction error on train set : 120.55385606448523\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(fit_intercept=False)\n",
    "lr_estimators = cross_validate(lr, X, y, return_estimator=True)['estimator']\n",
    "lr = cv_worst(lr_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying random forest regression with mae - poor implementation in sklearn with complexity in O(n^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 101.72239565267661\n",
      "Prediction error on train set : 101.34295766505343\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=1, max_depth=1, random_state=ransta, criterion='mae')\n",
    "rf_estimators = cross_validate(rf, X, y, return_estimator=True)['estimator']\n",
    "rf = cv_worst(rf_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying ridge regression : it does not improve the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 120.77430916869002\n",
      "Prediction error on train set : 120.55370740489916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=0.5, fit_intercept=False, random_state=ransta)\n",
    "ridge_estimators = cross_validate(ridge, X, y, return_estimator=True)['estimator']\n",
    "ridge = cv_worst(ridge_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying bayesian ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 120.77384668747833\n",
      "Prediction error on train set : 120.55362481624023\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "bay = BayesianRidge(fit_intercept=False)\n",
    "bay_estimators = cross_validate(bay, X, y, return_estimator=True)['estimator']\n",
    "bay = cv_worst(bay_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying generalized linear regression Power. Distribution\n",
    "0 : Normal.\n",
    "1 : Poisson.\n",
    "2 : Gamma.\n",
    "3 : Inverse Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 108.22684703433923\n",
      "Prediction error on train set : 107.76744685419798\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import TweedieRegressor\n",
    "gen = TweedieRegressor(power=2, alpha=1, link='log', fit_intercept=False)\n",
    "gen_estimators = cross_validate(gen, X, y, return_estimator=True)['estimator']\n",
    "gen = cv_worst(gen_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying passive aggressive regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 102.68593671715419\n",
      "Prediction error on train set : 102.19758510761302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveRegressor\n",
    "par = PassiveAggressiveRegressor(max_iter=100, random_state=ransta, tol=1e-3, fit_intercept=False)\n",
    "par_estimators = cross_validate(par, X, y, return_estimator=True)['estimator']\n",
    "par = cv_worst(par_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying gamma regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 120.2298146221143\n",
      "Prediction error on train set : 120.08248955253464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import GammaRegressor\n",
    "gam = GammaRegressor(alpha=0.001)\n",
    "gam_estimators = cross_validate(gam, X, y, return_estimator=True)['estimator']\n",
    "gam = cv_worst(gam_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying poisson regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 120.07962384861449\n",
      "Prediction error on train set : 119.89253563700633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "poi = PoissonRegressor(alpha=0.001)\n",
    "poi_estimators = cross_validate(poi, X, y, return_estimator=True)['estimator']\n",
    "poi = cv_worst(poi_estimators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying k-nn regression : why does it fool the cross validation ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 28.960342236096658\n",
      "Prediction error on train set : 27.83893559736377\n",
      "\n",
      "Prediction error on a train / test split : 129.66204185454967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=1)\n",
    "knn_estimators = cross_validate(knn, X, y, return_estimator=True)['estimator']\n",
    "knn = cv_worst(knn_estimators)\n",
    "knn.fit(X_train, y_train)\n",
    "p = knn.predict(X_test).astype(int)\n",
    "print(\"\\nPrediction error on a train / test split :\", mean_absolute_error(y_true=y_test, y_pred=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying logistic regression - I am not sure about what it does and how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction error on a train / test split : 104.29571819478167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "sample = 100\n",
    "logi = LogisticRegression()#penalty='l1', solver='saga', random_state=0, fit_intercept=False)\n",
    "logi.fit(X_train[:sample], y_train[:sample])\n",
    "p = logi.predict(X_test).astype(int)\n",
    "print(\"\\nPrediction error on a train / test split :\", mean_absolute_error(y_true=y_test, y_pred=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying neural network (MLP regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2076/2076 [==============================] - 1s 653us/step - loss: 105.5301 - mean_squared_error: 41675.7617 - val_loss: 103.8000 - val_mean_squared_error: 41253.1445\n",
      "Epoch 2/10\n",
      "2076/2076 [==============================] - 1s 575us/step - loss: 102.3029 - mean_squared_error: 39916.0273 - val_loss: 103.5453 - val_mean_squared_error: 40588.8008\n",
      "Epoch 3/10\n",
      "2076/2076 [==============================] - 1s 581us/step - loss: 102.1827 - mean_squared_error: 39791.9414 - val_loss: 103.5569 - val_mean_squared_error: 41063.7656\n",
      "Epoch 4/10\n",
      "2076/2076 [==============================] - 1s 587us/step - loss: 102.0614 - mean_squared_error: 39779.0156 - val_loss: 103.4340 - val_mean_squared_error: 40974.1055\n",
      "Epoch 5/10\n",
      "2076/2076 [==============================] - 1s 596us/step - loss: 101.9576 - mean_squared_error: 39703.5430 - val_loss: 103.2275 - val_mean_squared_error: 40584.3125\n",
      "Epoch 6/10\n",
      "2076/2076 [==============================] - 1s 592us/step - loss: 101.8243 - mean_squared_error: 39626.8516 - val_loss: 103.0645 - val_mean_squared_error: 40368.6211\n",
      "Epoch 7/10\n",
      "2076/2076 [==============================] - 1s 587us/step - loss: 101.6869 - mean_squared_error: 39537.0352 - val_loss: 102.9046 - val_mean_squared_error: 40167.6523\n",
      "Epoch 8/10\n",
      "2076/2076 [==============================] - 1s 589us/step - loss: 101.5361 - mean_squared_error: 39422.8945 - val_loss: 102.7760 - val_mean_squared_error: 40206.4844\n",
      "Epoch 9/10\n",
      "2076/2076 [==============================] - 1s 593us/step - loss: 101.4296 - mean_squared_error: 39322.9102 - val_loss: 102.6154 - val_mean_squared_error: 40047.7734\n",
      "Epoch 10/10\n",
      "2076/2076 [==============================] - 1s 581us/step - loss: 101.3187 - mean_squared_error: 39257.5703 - val_loss: 102.4535 - val_mean_squared_error: 39706.6250\n",
      "\n",
      "Prediction error on a train / test split : 101.47427448259914\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "mlp = Sequential()\n",
    "input_shape = X.iloc[0].shape\n",
    "mlp.add(Dense(16, input_shape=input_shape, activation='relu'))\n",
    "mlp.add(Dense(8, activation='relu'))\n",
    "mlp.add(Dense(1, activation='linear'))\n",
    "mlp.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "mlp.fit(X_test, y_test, epochs=10, batch_size=10, verbose=1, validation_split=0.2)\n",
    "p = mlp.predict(X_test).astype(int)\n",
    "print(\"\\nPrediction error on a train / test split :\", mean_absolute_error(y_true=y_test, y_pred=p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying SVM regression (too long, but seems to have nice results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction error on test set : 99.85828804871468\n",
      "Prediction error on train set : 99.49754711682992\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "sample = 10000\n",
    "svmr = svm.SVR(kernel='poly')\n",
    "svmr_estimators = cross_validate(svmr, X[:sample], y[:sample], return_estimator=True)['estimator']\n",
    "svmr = cv_worst(svmr_estimators)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
